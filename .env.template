###################################################
########## App. Dockerization Automation ##########
###################################################

#### ---------------------------------------------
#### ---- App:Specifications ----
#### ---- (DO NOT Change unless you know results)
#### ---------------------------------------------
APP_HOME=/home/developer/app
APP_MAIN=/home/developer/setup.sh

# -- Syntax: --
## build models: ant maven javac jar
APP_BUILD_MODEL=

# -- Command to run APP (java, python, nodejs etc.) : --
#APP_RUN_CMD=python -u myproj/<FOLDER>/__main__.py
#APP_RUN_CMD=java main.java
#### ---- NodeJS ---- #####
#### ---- DON'T use (double) quotes for the command! ----
#APP_RUN_CMD=node simple-server.js
APP_RUN_CMD=

#### ---------------------------------
#### ---- App:Container:Host:Info ----
#### ---------------------------------
DOCKER_HOST_IP={{DOCKER_HOST_IP}}
DOCKER_HOST_NAME={{DOCKER_HOST_NAME}}

###################################################
########### Container-based Platform ##############
###################################################

#### -------------------------------------
#### ---- Docker:Build:Specifications ----
#### -------------------------------------
# BUILD_VERSION=1.0.0
#USER_ID=1000
#GROUP_ID=1000
#INSTALL_BASE=/opt

#### -------------------------------------------------------------
#### ---- Docker:Run:Specifications ----
#### -------------------------------------------------------------
#### Ref: https://vsupalov.com/docker-arg-env-variable-guide/
#### Rider configuration for run.sh ####
# - Use "#VOLUMES" and "#PORTS" to indicate that the variables for run.sh"
# - To ignore line, use "##" (double) in the beginning, e.g. "##VOLUMES" and "##PORTS"
# - To indicate that the variables for run.sh", use only one "#",  e.g. "#VOLUMES" and "#PORTS"

#####################################
#### ---- NVIDIA Variables: ---- ####
#####################################
#### ref: https://github.com/NVIDIA/nvidia-docker/wiki/Installation-(Native-GPU-Support)#usage
#### set both NVIDIA_VISIBLE_DEVICES and NVIDIA_VISIBLE_DEVICES with GPU-IDs to control the GPUs available inside the container
#### In python code:
####   Setting CUDA_VISIBLE_DEVICES=1 mean your script will only see one GPU which is GPU1. However, 
####   inside your script it will be cuda:0 and not cuda:1. Because it only see one GPU and its index start at 0. 
####   For example if you do: CUDA_VISIBLE_DEVICES=2,4,5, your script will see 3 GPUs with index 0, 1, and 2 .
####
#### Note: (The following variables are already built-in cuda-pytorch-docker already!)
####
##TOKENIZERS_PARALLELISM=true
##NVIDIA_VISIBLE_DEVICES=all
#
##NVIDIA_VISIBLE_DEVICES=0
#
##CUDA_VISIBLE_DEVICES=all
##CUDA_VISIBLE_DEVICES=0
##CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7,8
#
##NVIDIA_DRIVER_CAPABILITIES=compute,video,utility

#### -------------------------------------------------------------
#### ---- Docker:Run:Specifications: Ports Mapping: ----
#### -------------------------------------------------------------
#### ---- You need to change to only 1 '#' to let "./run.sh" to interpret it.
##PORTS_LIST="18080:8000 17200:7200"
##PORTS_LIST="12781:12781"
##PORTS_LIST="1234:1234/udp"
##PORTS_LIST="8080:8080"

#### -------------------------------------------------------------
#### ---- Docker:Run:Specifications: Volumes Mapping: ----
#### -------------------------------------------------------------
##VOLUMES_LIST="./data:data ./workspace:workspace"
##VOLUMES_LIST="data workspace"
##VOLUMES_LIST="app data workspace /var/run/docker.sock:/var/run/docker.sock"
##VOLUMES_LIST="/var/run/docker.sock:/var/run/docker.sock app data workspace"
##VOLUMES_LIST="/run/dbus:/host/run/dbus ./data:data app:/home/developer/app workspace:workspace "
##VOLUMES_LIST="./app:app ./data:data ./workspace:workspace"
##VOLUMES_LIST="data workspace /dev/shm:/dev/shm /var/run/docker.sock:/var/run/docker.sock /tmp/.X11-unix:/tmp/.X11-unix"

#############################################################################
#### --- TO-DO HERE: Modify the line below to open the ports mapping: -- ####
#############################################################################
##VOLUMES_LIST="data workspace /dev/shm:/dev/shm /var/run/docker.sock:/var/run/docker.sock"
#VOLUMES_LIST="data workspace"
##VOLUMES_LIST="./.jupyter:/home/developer/.jupyter/jupyter_notebook_config.py data workspace"

## -- Tensorflow board is at 6006 (host port) --
## -- Jupyter Web UI is at 8888 (host port) --
#PORTS_LIST="6006:6006 8888:8888"

